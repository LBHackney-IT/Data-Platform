{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This Notebook Enriches the Joins the Officers and Teams tablue using the user teams mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv.append('--source_catalog_table')\n",
    "# TODO: set name of the source table name in the glue catalog \n",
    "sys.argv.append('dtf_locations')\n",
    "# changed to full file\n",
    "\n",
    "sys.argv.append('--source_catalog_table2')\n",
    "# TODO: set name of the source table name in the glue catalog \n",
    "sys.argv.append('unrestricted_address_api_dbo_hackney_address')\n",
    "# Changed to full file\n",
    "\n",
    "sys.argv.append('--source_catalog_database')\n",
    "# TODO: set name of the source database name in the glue catalog \n",
    "sys.argv.append('dataplatform-stg-tascomi-refined-zone')\n",
    "\n",
    "sys.argv.append('--source_catalog_database2')\n",
    "# TODO: set name of the source database name in the glue catalog \n",
    "sys.argv.append('dataplatform-stg-raw-zone-unrestricted-address-api')\n",
    "\n",
    "sys.argv.append('--s3_bucket_target')\n",
    "# TODO: set S3 location where the transformed data will be saved\n",
    "sys.argv.append('s3://dataplatform-stg-trusted-zone/tascomi/tables')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue.job import Job\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# from helper.helpers import get_glue_env_var,\n",
    "\n",
    "def get_glue_env_var(key, default=\"none\"):\n",
    "    if f'--{key}' in sys.argv:\n",
    "        return getResolvedOptions(sys.argv, [key])[key]\n",
    "    else:\n",
    "        return default\n",
    "\n",
    "glueContext = GlueContext(SparkContext.getOrCreate())\n",
    "job = Job(glueContext)\n",
    "\n",
    "\n",
    "# Define Source Data\n",
    "source_catalog_table = get_glue_env_var('source_catalog_table', '')\n",
    "source_catalog_table2 = get_glue_env_var('source_catalog_table2', '')\n",
    "\n",
    "source_catalog_database = get_glue_env_var('source_catalog_database', '')\n",
    "source_catalog_database2 = get_glue_env_var('source_catalog_database2', '')\n",
    "\n",
    "target_bucket = get_glue_env_var('s3_bucket_target', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def drop_null_columns(df):\n",
    "  \n",
    "    _df_length = df.count()\n",
    "    null_counts = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    to_drop = [k for k, v in null_counts.items() if v >= _df_length]\n",
    "    df = df.drop(*to_drop)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_latest_snapshot(df):\n",
    "    \n",
    "   df = df.where(col('snapshot_date') == df.select(max('snapshot_date')).first()[0])\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_latest_import(df):\n",
    "    \n",
    "   df = df.where(col('import_date') == df.select(max('import_date')).first()[0])\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load DTF Locations Table\n",
    "data_source = glueContext.create_dynamic_frame.from_catalog(\n",
    "    name_space=source_catalog_database,\n",
    "    table_name=source_catalog_table\n",
    " )\n",
    "\n",
    "# convert to a data frame\n",
    "df = data_source.toDF()\n",
    "\n",
    "\n",
    "# Rename columns\n",
    "df = df.withColumnRenamed(\"id\",\"dtf_location_id\") \\\n",
    "\n",
    "\n",
    "df = get_latest_snapshot(df)\n",
    "\n",
    "# Drop Columns containing Only Nulls \n",
    "# df = drop_null_columns(df)\n",
    "\n",
    "# Create Calculated Fields for Reporting\n",
    "\n",
    "df = df.withColumn('counter_location', lit(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapWard = {\n",
    "            \"Hoxton East and Shoreditch\": \"Hoxton East & Shoreditch\"\n",
    "            }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Address base Hackney Addresses Table\n",
    "data_source2 = glueContext.create_dynamic_frame.from_catalog(\n",
    "    name_space=source_catalog_database2,\n",
    "    table_name=source_catalog_table2\n",
    ")\n",
    "\n",
    "# convert to a data frame\n",
    "df2 = data_source2.toDF()\n",
    "\n",
    "# Get latest import\n",
    "\n",
    "df2 = get_latest_import(df2)\n",
    "\n",
    "# Keep Only Relevant Columns\n",
    "df2 = df2.select(\"uprn\",\n",
    "                 \"blpu_class\",\n",
    "                 \"lpi_key\",\n",
    "                 \"lpi_logical_status\",\n",
    "                 \"ward\",\n",
    "                 \"postcode\",\n",
    "                 \"line1\",\n",
    "                 \"line2\",\n",
    "                 \"line3\",\n",
    "                 \"line4\")\n",
    "\n",
    "#create combined address field\n",
    "df2 = df2.withColumn('llpg_address',concat(trim(col('line1')),\n",
    "                                         lit(\", \"),\n",
    "                                         trim(col('line2')),\n",
    "                                         lit(\", \"),\n",
    "                                         trim(col('line3')),\n",
    "                                         lit(\", \"),\n",
    "                                         trim(col('line4')),\n",
    "                                         lit(\", \"),\n",
    "                                         trim(col('postcode')),\n",
    "                                        ))\n",
    "\n",
    "\n",
    "# Rename Relevant Columns\n",
    "df2 = df2.withColumnRenamed(\"lpi_key\",\"llpg_lpi_key\") \\\n",
    "         .withColumnRenamed(\"blpu_class\",\"llpg_blpu_class\") \\\n",
    "         .withColumnRenamed(\"uprn\",\"llpg_uprn\") \\\n",
    "         .withColumnRenamed(\"lpi_logical_status\",\"llpg_logical_status\") \\\n",
    "         .withColumnRenamed(\"ward\",\"llpg_ward\") \\\n",
    "         .withColumnRenamed(\"postcode\",\"llpg_postcode\") \\\n",
    "         .withColumnRenamed(\"line1\",\"llpg_line1\") \\\n",
    "         .withColumnRenamed(\"line2\",\"llpg_line2\") \\\n",
    "         .withColumnRenamed(\"line3\",\"llpg_line3\") \\\n",
    "         .withColumnRenamed(\"line4\",\"llpg_line4\") \\\n",
    "\n",
    "# Duplicate ward column to apply mapping\n",
    "\n",
    "df2 = df2.withColumn('llpg_ward_map', col('llpg_ward').cast('string')) \\\n",
    "\n",
    "# Apply Mapping\n",
    "df2 = df2.replace(to_replace=mapWard, subset=['llpg_ward_map'])\n",
    "\n",
    "\n",
    "\n",
    "# Check Result\n",
    "# df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join\n",
    "\n",
    "df = df.join(df2,df.uprn ==  df2.llpg_uprn,\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to dynamic frame \n",
    "dyanmic_frame = DynamicFrame.fromDF(df, glueContext, \"target_data_to_write\")\n",
    "\n",
    "# Write the data to S3\n",
    "parquet_data = glueContext.write_dynamic_frame.from_options(\n",
    "    frame=dynamic_frame,\n",
    "    connection_type=\"s3\",\n",
    "    format=\"parquet\",\n",
    "    connection_options={\"path\": target_bucket, \"partitionKeys\": [\"import_year\", \"import_month\", \"import_day\", \"import_date\"]},\n",
    "    transformation_ctx=\"target_data_to_write\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
